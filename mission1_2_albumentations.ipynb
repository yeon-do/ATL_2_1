{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeon-do/ATL_2_1/blob/main/mission1_2_albumentations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8u-oicvynAZ",
        "outputId": "52b1afcb-da89-4c66-c49d-2f6ca5eb27a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IC0vMEG-yqzW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import time\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3Wjr5iLyt7w",
        "outputId": "5c02659e-120c-42a6-9aab-e6f08c500ea4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vZLN8rX5yv-T"
      },
      "outputs": [],
      "source": [
        "# 이미지가 저장된 경로 설정\n",
        "image_dir = '/content/drive/MyDrive/mission_data/training_image'   # train\n",
        "\n",
        "image_dir2 = '/content/drive/MyDrive/mission_data/validation_image'    # val"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfOVHaheV5W_"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mVlddcW0V5Jo",
        "outputId": "17a55b2c-1441-4b91-ca88-34ec6ded414c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"train_stats\",\n  \"rows\": 31,\n  \"fields\": [\n    {\n      \"column\": \"Gender\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"W\",\n          \"M\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Style\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"athleisure\",\n          \"kitsch\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 97,\n        \"min\": 31,\n        \"max\": 364,\n        \"num_unique_values\": 27,\n        \"samples\": [\n          153,\n          77\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "train_stats"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-012b3175-83d0-4e66-a8b7-5d643b986504\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gender</th>\n",
              "      <th>Style</th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M</td>\n",
              "      <td>hippie</td>\n",
              "      <td>260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>M</td>\n",
              "      <td>hiphop</td>\n",
              "      <td>274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M</td>\n",
              "      <td>normcore</td>\n",
              "      <td>364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>M</td>\n",
              "      <td>bold</td>\n",
              "      <td>268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>M</td>\n",
              "      <td>ivy</td>\n",
              "      <td>237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>M</td>\n",
              "      <td>mods</td>\n",
              "      <td>269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>M</td>\n",
              "      <td>metrosexual</td>\n",
              "      <td>278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>M</td>\n",
              "      <td>sportivecasual</td>\n",
              "      <td>298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>W</td>\n",
              "      <td>normcore</td>\n",
              "      <td>153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>W</td>\n",
              "      <td>hippie</td>\n",
              "      <td>91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>W</td>\n",
              "      <td>athleisure</td>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>W</td>\n",
              "      <td>sportivecasual</td>\n",
              "      <td>157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>W</td>\n",
              "      <td>ecology</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>W</td>\n",
              "      <td>classic</td>\n",
              "      <td>77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>W</td>\n",
              "      <td>minimal</td>\n",
              "      <td>139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>W</td>\n",
              "      <td>feminine</td>\n",
              "      <td>154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>W</td>\n",
              "      <td>kitsch</td>\n",
              "      <td>91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>W</td>\n",
              "      <td>lounge</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>W</td>\n",
              "      <td>bodyconscious</td>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>W</td>\n",
              "      <td>cityglam</td>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>W</td>\n",
              "      <td>genderless</td>\n",
              "      <td>77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>W</td>\n",
              "      <td>oriental</td>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>W</td>\n",
              "      <td>powersuit</td>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>W</td>\n",
              "      <td>military</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>W</td>\n",
              "      <td>punk</td>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>W</td>\n",
              "      <td>lingerie</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>W</td>\n",
              "      <td>hiphop</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>W</td>\n",
              "      <td>popart</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>W</td>\n",
              "      <td>disco</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>W</td>\n",
              "      <td>space</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>W</td>\n",
              "      <td>grunge</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-012b3175-83d0-4e66-a8b7-5d643b986504')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-012b3175-83d0-4e66-a8b7-5d643b986504 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-012b3175-83d0-4e66-a8b7-5d643b986504');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-10036100-648f-4f6a-abe4-deafbf77b721\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-10036100-648f-4f6a-abe4-deafbf77b721')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-10036100-648f-4f6a-abe4-deafbf77b721 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_7b95ab84-c921-4859-bd49-27926f461801\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_stats')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7b95ab84-c921-4859-bd49-27926f461801 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_stats');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   Gender           Style  Count\n",
              "0       M          hippie    260\n",
              "1       M          hiphop    274\n",
              "2       M        normcore    364\n",
              "3       M            bold    268\n",
              "4       M             ivy    237\n",
              "5       M            mods    269\n",
              "6       M     metrosexual    278\n",
              "7       M  sportivecasual    298\n",
              "8       W        normcore    153\n",
              "9       W          hippie     91\n",
              "10      W      athleisure     67\n",
              "11      W  sportivecasual    157\n",
              "12      W         ecology     64\n",
              "13      W         classic     77\n",
              "14      W         minimal    139\n",
              "15      W        feminine    154\n",
              "16      W          kitsch     91\n",
              "17      W          lounge     45\n",
              "18      W   bodyconscious     95\n",
              "19      W        cityglam     67\n",
              "20      W      genderless     77\n",
              "21      W        oriental     78\n",
              "22      W       powersuit    120\n",
              "23      W        military     33\n",
              "24      W            punk     65\n",
              "25      W        lingerie     55\n",
              "26      W          hiphop     48\n",
              "27      W          popart     41\n",
              "28      W           disco     37\n",
              "29      W           space     37\n",
              "30      W          grunge     31"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Validation Statistics:\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"val_stats\",\n  \"rows\": 31,\n  \"fields\": [\n    {\n      \"column\": \"Gender\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"M\",\n          \"W\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Style\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"genderless\",\n          \"athleisure\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 24,\n        \"min\": 5,\n        \"max\": 82,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          12,\n          66\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "val_stats"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-a30057f4-7876-4d9b-97b9-91ae06861b06\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gender</th>\n",
              "      <th>Style</th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>W</td>\n",
              "      <td>cityglam</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>W</td>\n",
              "      <td>feminine</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>W</td>\n",
              "      <td>kitsch</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>W</td>\n",
              "      <td>minimal</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>W</td>\n",
              "      <td>military</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>W</td>\n",
              "      <td>sportivecasual</td>\n",
              "      <td>48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>W</td>\n",
              "      <td>powersuit</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>W</td>\n",
              "      <td>hippie</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>W</td>\n",
              "      <td>genderless</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>W</td>\n",
              "      <td>oriental</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>W</td>\n",
              "      <td>grunge</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>W</td>\n",
              "      <td>bodyconscious</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>W</td>\n",
              "      <td>space</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>W</td>\n",
              "      <td>athleisure</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>W</td>\n",
              "      <td>punk</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>W</td>\n",
              "      <td>classic</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>W</td>\n",
              "      <td>disco</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>W</td>\n",
              "      <td>normcore</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>W</td>\n",
              "      <td>ecology</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>W</td>\n",
              "      <td>lingerie</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>W</td>\n",
              "      <td>popart</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>W</td>\n",
              "      <td>hiphop</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>W</td>\n",
              "      <td>lounge</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>M</td>\n",
              "      <td>hiphop</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>M</td>\n",
              "      <td>bold</td>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>M</td>\n",
              "      <td>hippie</td>\n",
              "      <td>82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>M</td>\n",
              "      <td>ivy</td>\n",
              "      <td>79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>M</td>\n",
              "      <td>metrosexual</td>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>M</td>\n",
              "      <td>mods</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>M</td>\n",
              "      <td>normcore</td>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>M</td>\n",
              "      <td>sportivecasual</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a30057f4-7876-4d9b-97b9-91ae06861b06')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a30057f4-7876-4d9b-97b9-91ae06861b06 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a30057f4-7876-4d9b-97b9-91ae06861b06');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0b16d4f5-d84c-4296-bde5-0dc249e4363c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0b16d4f5-d84c-4296-bde5-0dc249e4363c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0b16d4f5-d84c-4296-bde5-0dc249e4363c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_6b25dcda-4344-4d23-8308-a13a4ef668c8\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('val_stats')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6b25dcda-4344-4d23-8308-a13a4ef668c8 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('val_stats');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   Gender           Style  Count\n",
              "0       W        cityglam     18\n",
              "1       W        feminine     44\n",
              "2       W          kitsch     22\n",
              "3       W         minimal     35\n",
              "4       W        military      9\n",
              "5       W  sportivecasual     48\n",
              "6       W       powersuit     34\n",
              "7       W          hippie     14\n",
              "8       W      genderless     12\n",
              "9       W        oriental     18\n",
              "10      W          grunge     10\n",
              "11      W   bodyconscious     23\n",
              "12      W           space     15\n",
              "13      W      athleisure     14\n",
              "14      W            punk     12\n",
              "15      W         classic     22\n",
              "16      W           disco     10\n",
              "17      W        normcore     20\n",
              "18      W         ecology     17\n",
              "19      W        lingerie      5\n",
              "20      W          popart      8\n",
              "21      W          hiphop      8\n",
              "22      W          lounge      8\n",
              "23      M          hiphop     66\n",
              "24      M            bold     57\n",
              "25      M          hippie     82\n",
              "26      M             ivy     79\n",
              "27      M     metrosexual     58\n",
              "28      M            mods     80\n",
              "29      M        normcore     51\n",
              "30      M  sportivecasual     52"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "\n",
        "# 파일명을 파싱하여 성별과 스타일 정보를 추출하는 함수\n",
        "def parse_filename(filename):\n",
        "    # 파일명에서 확장자를 제거한 후 \"_\"로 분할\n",
        "    file_parts = filename.split('.')[0].split('_')\n",
        "    if len(file_parts) < 4:\n",
        "        print(f\"Filename format incorrect: {filename}\")\n",
        "        return None, None  # 파싱 실패 시 None 반환\n",
        "    # 성별과 스타일 추출\n",
        "    gender = file_parts[-1]  # 성별 (M or W)\n",
        "    style = file_parts[-2]  # 스타일\n",
        "    return gender, style\n",
        "\n",
        "# 폴더 내 모든 파일을 재귀적으로 탐색하며 성별 및 스타일 통계를 계산하는 함수\n",
        "def calculate_statistics(image_dir):\n",
        "    # 성별과 스타일별 카운트를 저장할 딕셔너리\n",
        "    stats = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "    # 이미지 폴더 내의 모든 파일을 재귀적으로 탐색\n",
        "    for root, _, files in os.walk(image_dir):\n",
        "        for filename in files:\n",
        "            if filename.endswith(\".jpg\"):\n",
        "                gender, style = parse_filename(filename)\n",
        "                if gender and style:  # 성별과 스타일이 파싱된 경우에만 처리\n",
        "                    stats[gender][style] += 1\n",
        "\n",
        "    # 성별, 스타일, 이미지 수로 구성된 DataFrame 생성\n",
        "    data = []\n",
        "    for gender, styles in stats.items():\n",
        "        for style, count in styles.items():\n",
        "            if gender and style:  # 파싱된 값이 유효할 때만 추가\n",
        "                data.append([gender, style, count])\n",
        "\n",
        "    if not data:\n",
        "        print(f\"No valid data found in directory: {image_dir}\")\n",
        "        return pd.DataFrame(columns=[\"Gender\", \"Style\", \"Count\"])\n",
        "\n",
        "    df = pd.DataFrame(data, columns=[\"Gender\", \"Style\", \"Count\"])\n",
        "    return df\n",
        "\n",
        "train_stats = calculate_statistics(image_dir)\n",
        "\n",
        "\n",
        "val_stats = calculate_statistics(image_dir2)\n",
        "\n",
        "# 결과 출력\n",
        "display(train_stats)\n",
        "\n",
        "print(\"\\nValidation Statistics:\")\n",
        "val_stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z895kVqC08Dx"
      },
      "source": [
        "## 변경된 코드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGuVBnR31em8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms\n",
        "from tqdm import tqdm  # tqdm을 사용하여 진행 상황 표시\n",
        "\n",
        "# 1. 커스텀 데이터셋 클래스 정의 (합쳐진 데이터셋)\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, img_dir, transform=None):\n",
        "        \"\"\"\n",
        "        img_dir: 이미지가 합쳐져 있는 디렉토리\n",
        "        transform: 이미지 전처리 변환\n",
        "        \"\"\"\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        # 이미지 파일 목록 불러오기 (성별과 상관없이 모두)\n",
        "        self.images = [img for img in os.listdir(img_dir) if img.endswith('.jpg')]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # 이미지 경로와 파일명\n",
        "        img_path = os.path.join(self.img_dir, self.images[idx])\n",
        "        image = Image.open(img_path).convert(\"RGB\")  # 이미지를 RGB로 변환\n",
        "\n",
        "        # 파일 이름으로 성별 레이블 결정 (예: 파일 이름에 'W'가 포함되면 여성, 'M'이면 남성)\n",
        "        if 'W' in self.images[idx]:\n",
        "            gender_label = 0  # W로 시작하는 파일은 성별 0 (여성)\n",
        "        elif 'M' in self.images[idx]:\n",
        "            gender_label = 1  # M로 시작하는 파일은 성별 1 (남성)\n",
        "        else:\n",
        "            raise ValueError(\"파일 이름에 성별을 구분할 수 있는 정보가 없습니다.\")\n",
        "\n",
        "        # 스타일 레이블을 임의로 지정 (2개의 스타일로 가정)\n",
        "        style_label = torch.randint(0, 2, (1,)).item()\n",
        "\n",
        "        # 이미지 전처리 적용\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, gender_label, style_label\n",
        "\n",
        "# 2. 데이터 전처리 정의\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# 3. 데이터셋 로드 (이미지들이 하나의 디렉토리에 있는 경우)\n",
        "train_dataset = CustomImageDataset(image_dir, transform=train_transforms)\n",
        "val_dataset = CustomImageDataset(image_dir2, transform=val_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2_VByPF02hi",
        "outputId": "af0a8519-34c4-4104-9241-b674c48f6916"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "# 4. ResNet-18 모델 설정 (다중 출력 분류)\n",
        "class MultiOutputResNet(nn.Module):\n",
        "    def __init__(self, num_gender_classes, num_style_classes):\n",
        "        super(MultiOutputResNet, self).__init__()\n",
        "        self.resnet = models.resnet18(pretrained=False)\n",
        "\n",
        "        # fully connected 레이어 삭제 및 성별/스타일 레이어 추가\n",
        "        in_features = self.resnet.fc.in_features\n",
        "        self.resnet.fc = nn.Identity()  # 기존 fully connected 레이어 비활성화\n",
        "        self.fc_gender = nn.Linear(in_features, num_gender_classes)  # 성별 분류 레이어\n",
        "        self.fc_style = nn.Linear(in_features, num_style_classes)    # 스타일 분류 레이어\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.resnet(x)  # ResNet을 통해 특징 추출\n",
        "        gender_output = self.fc_gender(features)  # 성별 분류\n",
        "        style_output = self.fc_style(features)    # 스타일 분류\n",
        "        return gender_output, style_output\n",
        "\n",
        "# 5. 모델 생성\n",
        "model = MultiOutputResNet(num_gender_classes=2, num_style_classes=2)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# 손실 함수와 옵티마이저 설정\n",
        "criterion_gender = nn.CrossEntropyLoss()\n",
        "criterion_style = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 6. 학습 과정 정의 (진행 퍼센트 표시)\n",
        "def train(model, train_loader, criterion_gender, criterion_style, optimizer):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_gender = 0\n",
        "    correct_style = 0\n",
        "    total = 0\n",
        "\n",
        "    # tqdm을 사용하여 진행 상황 표시\n",
        "    train_loader_tqdm = tqdm(train_loader, desc=\"Training\", unit=\"batch\")\n",
        "\n",
        "    for images, gender_labels, style_labels in train_loader_tqdm:\n",
        "        images, gender_labels, style_labels = images.to(device), gender_labels.to(device), style_labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 순전파\n",
        "        gender_outputs, style_outputs = model(images)\n",
        "\n",
        "        # 성별과 스타일에 대한 손실 각각 계산\n",
        "        loss_gender = criterion_gender(gender_outputs, gender_labels)\n",
        "        loss_style = criterion_style(style_outputs, style_labels)\n",
        "        loss = loss_gender + loss_style  # 총 손실은 두 손실의 합\n",
        "\n",
        "        # 역전파 및 최적화\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted_gender = torch.max(gender_outputs, 1)\n",
        "        _, predicted_style = torch.max(style_outputs, 1)\n",
        "\n",
        "        total += gender_labels.size(0)\n",
        "        correct_gender += (predicted_gender == gender_labels).sum().item()\n",
        "        correct_style += (predicted_style == style_labels).sum().item()\n",
        "\n",
        "        # 진행 상태를 표시할 때도 정확도나 손실 등을 업데이트\n",
        "        train_loader_tqdm.set_postfix(loss=loss.item(), gender_acc=correct_gender/total, style_acc=correct_style/total)\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    gender_accuracy = correct_gender / total\n",
        "    style_accuracy = correct_style / total\n",
        "    return avg_loss, gender_accuracy, style_accuracy\n",
        "\n",
        "# 7. 검증 과정 정의\n",
        "def validate(model, val_loader, criterion_gender, criterion_style):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct_gender = 0\n",
        "    correct_style = 0\n",
        "    total = 0\n",
        "\n",
        "    # tqdm을 사용하여 진행 상황 표시\n",
        "    val_loader_tqdm = tqdm(val_loader, desc=\"Validation\", unit=\"batch\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, gender_labels, style_labels in val_loader_tqdm:\n",
        "            images, gender_labels, style_labels = images.to(device), gender_labels.to(device), style_labels.to(device)\n",
        "\n",
        "            gender_outputs, style_outputs = model(images)\n",
        "\n",
        "            loss_gender = criterion_gender(gender_outputs, gender_labels)\n",
        "            loss_style = criterion_style(style_outputs, style_labels)\n",
        "            loss = loss_gender + loss_style\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            _, predicted_gender = torch.max(gender_outputs, 1)\n",
        "            _, predicted_style = torch.max(style_outputs, 1)\n",
        "\n",
        "            total += gender_labels.size(0)\n",
        "            correct_gender += (predicted_gender == gender_labels).sum().item()\n",
        "            correct_style += (predicted_style == style_labels).sum().item()\n",
        "\n",
        "            # 진행 상태를 표시할 때도 정확도나 손실 등을 업데이트\n",
        "            val_loader_tqdm.set_postfix(loss=loss.item(), gender_acc=correct_gender/total, style_acc=correct_style/total)\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    gender_accuracy = correct_gender / total\n",
        "    style_accuracy = correct_style / total\n",
        "    return avg_val_loss, gender_accuracy, style_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lvvcWsK1bax"
      },
      "outputs": [],
      "source": [
        "# 8. 모델 학습 실행\n",
        "def train_model(model, train_loader, val_loader, criterion_gender, criterion_style, optimizer, num_epochs=10):\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
        "\n",
        "        # 학습 단계\n",
        "        train_loss, train_gender_acc, train_style_acc = train(\n",
        "            model, train_loader, criterion_gender, criterion_style, optimizer\n",
        "        )\n",
        "\n",
        "        # 검증 단계\n",
        "        val_loss, val_gender_acc, val_style_acc = validate(\n",
        "            model, val_loader, criterion_gender, criterion_style\n",
        "        )\n",
        "\n",
        "        # 에폭별 결과 출력\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] - \"\n",
        "              f\"Train Loss: {train_loss:.4f}, Train Gender Acc: {train_gender_acc:.4f}, Train Style Acc: {train_style_acc:.4f}\")\n",
        "        print(f\"Validation Loss: {val_loss:.4f}, Validation Gender Acc: {val_gender_acc:.4f}, Validation Style Acc: {val_style_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 987
        },
        "id": "_ib8ZIqC17fm",
        "outputId": "2c31c827-5e05-40f0-b18e-13f6894dbdd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 128/128 [57:06<00:00, 26.77s/batch, gender_acc=0.989, loss=0.814, style_acc=0.497]\n",
            "Validation: 100%|██████████| 30/30 [13:54<00:00, 27.81s/batch, gender_acc=0.993, loss=0.722, style_acc=0.524]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10] - Train Loss: 0.8271, Train Gender Acc: 0.9892, Train Style Acc: 0.4968\n",
            "Validation Loss: 0.7346, Validation Gender Acc: 0.9926, Validation Style Acc: 0.5237\n",
            "Epoch [2/10]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 128/128 [36:15<00:00, 16.99s/batch, gender_acc=0.995, loss=0.827, style_acc=0.506]\n",
            "Validation: 100%|██████████| 30/30 [05:42<00:00, 11.43s/batch, gender_acc=0.993, loss=0.774, style_acc=0.507]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10] - Train Loss: 0.7399, Train Gender Acc: 0.9946, Train Style Acc: 0.5064\n",
            "Validation Loss: 0.7510, Validation Gender Acc: 0.9926, Validation Style Acc: 0.5068\n",
            "Epoch [3/10]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 128/128 [36:23<00:00, 17.06s/batch, gender_acc=0.995, loss=0.529, style_acc=0.504]\n",
            "Validation: 100%|██████████| 30/30 [05:40<00:00, 11.35s/batch, gender_acc=0.993, loss=0.816, style_acc=0.498]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10] - Train Loss: 0.7340, Train Gender Acc: 0.9946, Train Style Acc: 0.5039\n",
            "Validation Loss: 0.7780, Validation Gender Acc: 0.9926, Validation Style Acc: 0.4984\n",
            "Epoch [4/10]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 128/128 [36:21<00:00, 17.04s/batch, gender_acc=0.995, loss=0.684, style_acc=0.504]\n",
            "Validation: 100%|██████████| 30/30 [05:40<00:00, 11.37s/batch, gender_acc=0.993, loss=0.718, style_acc=0.507]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10] - Train Loss: 0.7405, Train Gender Acc: 0.9946, Train Style Acc: 0.5039\n",
            "Validation Loss: 0.7356, Validation Gender Acc: 0.9926, Validation Style Acc: 0.5068\n",
            "Epoch [5/10]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 128/128 [36:20<00:00, 17.04s/batch, gender_acc=0.995, loss=0.743, style_acc=0.502]\n",
            "Validation: 100%|██████████| 30/30 [05:42<00:00, 11.40s/batch, gender_acc=0.993, loss=0.741, style_acc=0.499]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10] - Train Loss: 0.7294, Train Gender Acc: 0.9946, Train Style Acc: 0.5022\n",
            "Validation Loss: 0.7471, Validation Gender Acc: 0.9926, Validation Style Acc: 0.4995\n",
            "Epoch [6/10]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 128/128 [35:58<00:00, 16.86s/batch, gender_acc=0.995, loss=0.781, style_acc=0.501]\n",
            "Validation: 100%|██████████| 30/30 [05:37<00:00, 11.24s/batch, gender_acc=0.993, loss=0.693, style_acc=0.503]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10] - Train Loss: 0.7332, Train Gender Acc: 0.9946, Train Style Acc: 0.5007\n",
            "Validation Loss: 0.7291, Validation Gender Acc: 0.9926, Validation Style Acc: 0.5026\n",
            "Epoch [7/10]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 128/128 [36:00<00:00, 16.88s/batch, gender_acc=0.995, loss=0.713, style_acc=0.508]\n",
            "Validation: 100%|██████████| 30/30 [05:37<00:00, 11.25s/batch, gender_acc=0.993, loss=0.736, style_acc=0.493]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10] - Train Loss: 0.7272, Train Gender Acc: 0.9946, Train Style Acc: 0.5084\n",
            "Validation Loss: 0.7274, Validation Gender Acc: 0.9926, Validation Style Acc: 0.4932\n",
            "Epoch [8/10]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   2%|▏         | 2/128 [00:47<50:03, 23.84s/batch, gender_acc=1, loss=0.72, style_acc=0.438]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-ba63b9ef306e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 9. 학습 실행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_gender\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_style\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-49c3fdf31e50>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, criterion_gender, criterion_style, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m# 학습 단계\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         train_loss, train_gender_acc, train_style_acc = train(\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_gender\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_style\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         )\n",
            "\u001b[0;32m<ipython-input-9-d786ade693c2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, criterion_gender, criterion_style, optimizer)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# 순전파\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mgender_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# 성별과 스타일에 대한 손실 각각 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-d786ade693c2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# ResNet을 통해 특징 추출\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mgender_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_gender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 성별 분류\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mstyle_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_style\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# 스타일 분류\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 454\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    455\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# 9. 학습 실행\n",
        "train_model(model, train_loader, val_loader, criterion_gender, criterion_style, optimizer, num_epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9mo6lZ92A3p"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaKjbsmX-zsq"
      },
      "source": [
        "### try 5\n",
        "\n",
        "optimizer 학습률 작게 조정, albumentations 모듈 변환기 사용해 이미지 증강, 정규화 기법 추가(drop out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OENfKd6KAtm3",
        "outputId": "e3d1c8cf-672e-4702-8059-515fc91e4b05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (1.4.15)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (1.13.1)\n",
            "Requirement already satisfied: scikit-image>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.24.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations) (6.0.2)\n",
            "Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from albumentations) (2.9.2)\n",
            "Requirement already satisfied: albucore>=0.0.15 in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.0.16)\n",
            "Requirement already satisfied: eval-type-backport in /usr/local/lib/python3.10/dist-packages (from albumentations) (0.2.0)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations) (4.10.0.84)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations) (4.12.2)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (3.3)\n",
            "Requirement already satisfied: pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (10.4.0)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (2.35.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (2024.9.20)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (24.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations) (0.4)\n",
            "Requirement already satisfied: albumentations[imgaug] in /usr/local/lib/python3.10/dist-packages (1.4.15)\n",
            "Collecting albumentations[imgaug]\n",
            "  Downloading albumentations-1.4.17-py3-none-any.whl.metadata (38 kB)\n",
            "\u001b[33mWARNING: albumentations 1.4.17 does not provide the extra 'imgaug'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from albumentations[imgaug]) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations[imgaug]) (1.13.1)\n",
            "Requirement already satisfied: scikit-image>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from albumentations[imgaug]) (0.24.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations[imgaug]) (6.0.2)\n",
            "Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from albumentations[imgaug]) (2.9.2)\n",
            "Collecting albucore==0.0.17 (from albumentations[imgaug])\n",
            "  Downloading albucore-0.0.17-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: eval-type-backport in /usr/local/lib/python3.10/dist-packages (from albumentations[imgaug]) (0.2.0)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations[imgaug]) (4.10.0.84)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations[imgaug]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations[imgaug]) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations[imgaug]) (4.12.2)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations[imgaug]) (3.3)\n",
            "Requirement already satisfied: pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations[imgaug]) (10.4.0)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations[imgaug]) (2.35.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations[imgaug]) (2024.9.20)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations[imgaug]) (24.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations[imgaug]) (0.4)\n",
            "Downloading albucore-0.0.17-py3-none-any.whl (10 kB)\n",
            "Downloading albumentations-1.4.17-py3-none-any.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: albucore, albumentations\n",
            "  Attempting uninstall: albucore\n",
            "    Found existing installation: albucore 0.0.16\n",
            "    Uninstalling albucore-0.0.16:\n",
            "      Successfully uninstalled albucore-0.0.16\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 1.4.15\n",
            "    Uninstalling albumentations-1.4.15:\n",
            "      Successfully uninstalled albumentations-1.4.15\n",
            "Successfully installed albucore-0.0.17 albumentations-1.4.17\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install albumentations\n",
        "!pip install --upgrade albumentations[imgaug]  # 추가적인 이미지 증강 도구 사용 가능\n",
        "!pip install opencv-python-headless  # OpenCV 설치 (Albumentations에서 필요)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EViJhW7W-1fI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms\n",
        "from tqdm import tqdm  # tqdm을 사용하여 진행 상황 표시\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "\n",
        "# 1. Albumentations를 이용한 데이터 전처리 및 증강\n",
        "# 학습용 데이터 전처리 정의 (여러 증강 기법 포함)\n",
        "train_transforms = A.Compose([\n",
        "    A.Resize(224, 224),  # 크기 조정\n",
        "    A.HorizontalFlip(p=0.5),  # 50% 확률로 좌우 반전\n",
        "    A.VerticalFlip(p=0.5),  # 상하 반전 추가\n",
        "    A.RandomBrightnessContrast(p=0.2),  # 밝기 및 대비 조절\n",
        "    A.Rotate(limit=30, p=0.5),  # -30도에서 30도까지 랜덤 회전\n",
        "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=30, p=0.5),  # 이동, 확대/축소, 회전\n",
        "    A.GaussianBlur(p=0.3),  # 가우시안 블러 추가\n",
        "    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2, p=0.5),  # 색상 변화 추가\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),  # ImageNet 정규화\n",
        "    ToTensorV2(),  # PyTorch 텐서로 변환\n",
        "])\n",
        "\n",
        "# 검증용 데이터 전처리 정의 (증강 없이 정규화만 적용)\n",
        "val_transforms = A.Compose([\n",
        "    A.Resize(224, 224),  # 크기 조정\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),  # ImageNet 정규화\n",
        "    ToTensorV2(),  # PyTorch 텐서로 변환\n",
        "])\n",
        "\n",
        "\n",
        "# 2. 파일 이름을 이용한 클래스 및 레이블 구분\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, img_dir, transform=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.images = [img for img in os.listdir(img_dir) if img.endswith('.jpg')]\n",
        "\n",
        "        # 1. 데이터셋 내에서 고유한 스타일 문자열을 추출하여 정수로 매핑\n",
        "        self.style_map = self._create_style_map()\n",
        "\n",
        "        # **스타일 맵을 출력하여 확인**\n",
        "        #print(f\"Style Map: {self.style_map}\")\n",
        "\n",
        "    def _create_style_map(self):\n",
        "        # 스타일별 문자열을 추출하여 고유한 스타일을 정수로 매핑하는 딕셔너리 생성\n",
        "        style_set = set()  # 중복을 제거하기 위해 set 사용\n",
        "        for img in self.images:\n",
        "            parts = img.split('_')\n",
        "            style_set.add(parts[3])  # 네 번째 항목이 스타일\n",
        "\n",
        "        # 스타일 문자열을 정수로 매핑하는 딕셔너리 생성\n",
        "        style_map = {style: idx for idx, style in enumerate(sorted(style_set))}\n",
        "        return style_map\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      img_path = os.path.join(self.img_dir, self.images[idx])\n",
        "      image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
        "\n",
        "      filename = os.path.basename(img_path)\n",
        "      parts = filename.split('_')\n",
        "\n",
        "      # 성별 레이블 추출\n",
        "      gender_label = 0 if parts[4].startswith('W') else 1  # 성별 레이블: W -> 0, M -> 1\n",
        "\n",
        "      # 스타일 레이블 추출 (성별에 따라 다른 스타일 레이블을 정수로 변환)\n",
        "      style_label_str = parts[3]\n",
        "      style_label = self.style_map.get(style_label_str, -1)  # 문자열을 정수로 변환, 없으면 -1 반환\n",
        "\n",
        "      # 남성 스타일은 0~7, 여성 스타일은 0~21 범위 내에 있어야 함\n",
        "      if gender_label == 1:  # 남성\n",
        "        if style_label > 7:  # 남성 스타일 범위를 벗어났는지 확인\n",
        "            raise ValueError(f\"Style '{style_label_str}' for male is out of bounds\")\n",
        "      else:  # 여성\n",
        "        if style_label > 21:  # 여성 스타일 범위를 벗어났는지 확인\n",
        "            raise ValueError(f\"Style '{style_label_str}' for female is out of bounds\")\n",
        "\n",
        "      if style_label == -1:\n",
        "        raise ValueError(f\"Style '{style_label_str}' not found in style_map.\")\n",
        "\n",
        "      if self.transform:\n",
        "          augmented = self.transform(image=image)\n",
        "          image = augmented['image']\n",
        "\n",
        "      return image, gender_label, style_label\n",
        "\n",
        "\n",
        "# 3. 데이터셋 로드 (이미지들이 하나의 디렉토리에 있는 경우)\n",
        "train_dataset = CustomImageDataset(image_dir, transform=train_transforms)\n",
        "val_dataset = CustomImageDataset(image_dir2, transform=val_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQ8f6wdzAGs3"
      },
      "outputs": [],
      "source": [
        "# 4. ResNet-18 모델 설정 (다중 출력 분류)\n",
        "\n",
        "class MultiOutputResNet(nn.Module):\n",
        "    def __init__(self, num_gender_classes=2, num_male_styles=8, num_female_styles=22, dropout_prob=0.5):\n",
        "        super(MultiOutputResNet, self).__init__()\n",
        "        self.resnet = models.resnet18(pretrained=False)\n",
        "\n",
        "        # ResNet의 fully connected 레이어 삭제\n",
        "        in_features = self.resnet.fc.in_features\n",
        "        self.resnet.fc = nn.Identity()  # 기존 fully connected 레이어 제거\n",
        "\n",
        "        # Dropout 레이어 추가 (확률 50%)\n",
        "        self.dropout = nn.Dropout(p=dropout_prob)\n",
        "\n",
        "        # 성별 분류 레이어\n",
        "        self.fc_gender = nn.Linear(in_features, num_gender_classes)  # 성별 분류 (2개 클래스: W, T)\n",
        "\n",
        "        # 성별에 따른 스타일 분류 레이어\n",
        "        self.fc_male_style = nn.Linear(in_features, num_male_styles)    # 남성 스타일 분류\n",
        "        self.fc_female_style = nn.Linear(in_features, num_female_styles) # 여성 스타일 분류\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.resnet(x)\n",
        "\n",
        "        # Dropout 적용\n",
        "        features = self.dropout(features)\n",
        "\n",
        "        # 성별 분류\n",
        "        gender_output = self.fc_gender(features)\n",
        "\n",
        "        # 남성 스타일 분류\n",
        "        male_style_output = self.fc_male_style(features)\n",
        "        # 여성 스타일 분류\n",
        "        female_style_output = self.fc_female_style(features)\n",
        "\n",
        "        return gender_output, male_style_output, female_style_output\n",
        "\n",
        "\n",
        "# 5. 모델 생성 및 가중치 초기화\n",
        "#가중치 초기화 함수\n",
        "def initialize_weights(model):\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, nn.Linear):\n",
        "            torch.nn.init.xavier_uniform_(m.weight)  # Xavier 초기화 (Glorot 초기화)\n",
        "            if m.bias is not None:\n",
        "                torch.nn.init.zeros_(m.bias)  # bias는 0으로 초기화\n",
        "\n",
        "# 모델 생성 후 가중치 초기화 적용\n",
        "num_male_styles = 8   # 남성 스타일 개수\n",
        "num_female_styles = 22 # 여성 스타일 개수\n",
        "model = MultiOutputResNet(num_gender_classes=2, num_male_styles=num_male_styles, num_female_styles=num_female_styles, dropout_prob=0.5)\n",
        "model.apply(initialize_weights)  # 가중치 초기화 수행\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# 손실 함수와 옵티마이저 설정\n",
        "criterion_gender = nn.CrossEntropyLoss()\n",
        "criterion_style = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 6. 학습 과정 정의 (진행 퍼센트 표시)\n",
        "def train(model, train_loader, criterion_gender, criterion_style, optimizer):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_gender = 0\n",
        "    correct_style = 0\n",
        "    total = 0\n",
        "\n",
        "    # tqdm을 사용하여 진행 상황 표시\n",
        "    train_loader_tqdm = tqdm(train_loader, desc=\"Training\", unit=\"batch\")\n",
        "\n",
        "    for images, gender_labels, style_labels in train_loader_tqdm:\n",
        "        images, gender_labels, style_labels = images.to(device), gender_labels.to(device), style_labels.to(device)\n",
        "\n",
        "        # **타겟 레이블 확인**\n",
        "        #print(f\"Gender Labels (Max): {gender_labels.max().item()}, Style Labels (Max): {style_labels.max().item()}\")\n",
        "        #print(f\"Gender Labels (Min): {gender_labels.min().item()}, Style Labels (Min): {style_labels.min().item()}\")\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 순전파\n",
        "        gender_output, male_style_output, female_style_output = model(images)\n",
        "\n",
        "        # 성별에 따른 손실 계산\n",
        "        loss_gender = criterion_gender(gender_output, gender_labels)\n",
        "        loss_style = 0\n",
        "\n",
        "        #스타일에 따른 손실 계산\n",
        "        for i in range(gender_labels.size(0)):\n",
        "            if gender_labels[i] == 0:  # 여성일 때\n",
        "                loss_style += criterion_style(female_style_output[i].unsqueeze(0), style_labels[i].unsqueeze(0))\n",
        "            else:  # 남성일 때\n",
        "                loss_style += criterion_style(male_style_output[i].unsqueeze(0), style_labels[i].unsqueeze(0))\n",
        "\n",
        "        loss = loss_gender + loss_style  # 총 손실은 성별과 스타일 손실의 합\n",
        "\n",
        "        # 역전파 및 최적화\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted_gender = torch.max(gender_output, 1)\n",
        "\n",
        "        total += gender_labels.size(0)\n",
        "        correct_gender += (predicted_gender == gender_labels).sum().item()\n",
        "\n",
        "\n",
        "        # 진행 상태를 표시할 때도 정확도나 손실 등을 업데이트\n",
        "        train_loader_tqdm.set_postfix(loss=loss.item(), gender_acc=correct_gender / total)\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    gender_accuracy = correct_gender / total\n",
        "    return avg_loss, gender_accuracy\n",
        "\n",
        "\n",
        "# 7. 검증 과정 정의\n",
        "def validate(model, val_loader, criterion_gender, criterion_style):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct_gender = 0\n",
        "    correct_style = 0\n",
        "    total = 0\n",
        "\n",
        "    # tqdm을 사용하여 진행 상황 표시\n",
        "    val_loader_tqdm = tqdm(val_loader, desc=\"Validation\", unit=\"batch\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, gender_labels, style_labels in val_loader_tqdm:\n",
        "            images, gender_labels, style_labels = images.to(device), gender_labels.to(device), style_labels.to(device)\n",
        "\n",
        "            gender_output, male_style_output, female_style_output = model(images)\n",
        "\n",
        "            loss_gender = criterion_gender(gender_output, gender_labels)\n",
        "            loss_style = 0\n",
        "\n",
        "            for i in range(gender_labels.size(0)):\n",
        "                if gender_labels[i] == 0:\n",
        "                    loss_style += criterion_style(female_style_output[i].unsqueeze(0), style_labels[i].unsqueeze(0))\n",
        "                else:\n",
        "                    loss_style += criterion_style(male_style_output[i].unsqueeze(0), style_labels[i].unsqueeze(0))\n",
        "\n",
        "            loss = loss_gender + loss_style\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            _, predicted_gender = torch.max(gender_output, 1)\n",
        "\n",
        "            total += gender_labels.size(0)\n",
        "            correct_gender += (predicted_gender == gender_labels).sum().item()\n",
        "\n",
        "\n",
        "            # 진행 상태를 표시할 때도 정확도나 손실 등을 업데이트\n",
        "            val_loader_tqdm.set_postfix(loss=loss.item(), gender_acc=correct_gender / total)\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    gender_accuracy = correct_gender / total\n",
        "    return avg_val_loss, gender_accuracy\n",
        "\n",
        "# 8. 학습 실행\n",
        "    def train_model(model, train_loader, val_loader, criterion_gender, criterion_style, optimizer, num_epochs=10):\n",
        "      for epoch in range(num_epochs):\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "        avg_loss, gender_acc = train(model, train_loader, criterion_gender, criterion_style, optimizer)\n",
        "        print(f\"Training - Loss: {avg_loss:.4f}, Gender Accuracy: {gender_acc:.4f}\")\n",
        "\n",
        "        avg_val_loss, val_gender_acc = validate(model, val_loader, criterion_gender, criterion_style)\n",
        "        print(f\"Validation - Loss: {avg_val_loss:.4f}, Gender Accuracy: {val_gender_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "hocIAswOANQx",
        "outputId": "2bc59c82-c4b8-446a-cb3f-62a88e2d54ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/128 [00:00<?, ?batch/s]\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Style 'mods' for male is out of bounds",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-42fc875ec056>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_gender\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_style\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-41-25c918fbf4c3>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, criterion_gender, criterion_style, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1}/{num_epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mavg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgender_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_gender\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_style\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training - Loss: {avg_loss:.4f}, Gender Accuracy: {gender_acc:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-17d20ea4cf4f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, criterion_gender, criterion_style, optimizer)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mtrain_loader_tqdm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgender_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle_labels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader_tqdm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgender_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgender_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-3c1a434e5d51>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     77\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgender_label\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 남성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstyle_label\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 남성 스타일 범위를 벗어났는지 확인\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Style '{style_label_str}' for male is out of bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 여성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstyle_label\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m21\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 여성 스타일 범위를 벗어났는지 확인\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Style 'mods' for male is out of bounds"
          ]
        }
      ],
      "source": [
        "# 9. 학습 및 검증 데이터 로더 설정 후 학습 실행\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "train_model(model, train_loader, val_loader, criterion_gender, criterion_style, optimizer, num_epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4EunwibC6JN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5aIibH90hEM"
      },
      "source": [
        "### 최종1 with albumentations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MBdriY4nUbTv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms\n",
        "from tqdm import tqdm  # tqdm을 사용하여 진행 상황 표시\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "\n",
        "\n",
        "# 1. Albumentations를 이용한 데이터 전처리 및 증강\n",
        "# 학습용 데이터 전처리 정의 (여러 증강 기법 포함)\n",
        "train_transforms = A.Compose([\n",
        "    A.Resize(224, 224),  # 크기 조정\n",
        "    A.HorizontalFlip(p=0.5),  # 50% 확률로 좌우 반전\n",
        "    A.VerticalFlip(p=0.5),  # 상하 반전 추가\n",
        "    A.RandomBrightnessContrast(p=0.2),  # 밝기 및 대비 조절\n",
        "    A.Rotate(limit=30, p=0.5),  # -30도에서 30도까지 랜덤 회전\n",
        "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=30, p=0.5),  # 이동, 확대/축소, 회전\n",
        "    A.GaussianBlur(p=0.3),  # 가우시안 블러 추가\n",
        "    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2, p=0.5),  # 색상 변화 추가\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),  # ImageNet 정규화\n",
        "    ToTensorV2(),  # PyTorch 텐서로 변환\n",
        "])\n",
        "\n",
        "# 검증용 데이터 전처리 정의 (증강 없이 정규화만 적용)\n",
        "val_transforms = A.Compose([\n",
        "    A.Resize(224, 224),  # 크기 조정\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),  # ImageNet 정규화\n",
        "    ToTensorV2(),  # PyTorch 텐서로 변환\n",
        "])\n",
        "\n",
        "\n",
        "# 2. 파일 이름을 이용한 클래스 및 레이블 구분\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, img_dir, transform=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.images = [img\n",
        "        for img in os.listdir(img_dir) if img.endswith('.jpg')]\n",
        "\n",
        "        # 남성과 여성의 스타일을 구분하여 각각 매핑\n",
        "        self.male_style_map = self._create_male_style_map()\n",
        "        self.female_style_map = self._create_female_style_map()\n",
        "\n",
        "    def _create_male_style_map(self):\n",
        "        # 남성 스타일 목록에 따라 정수로 매핑\n",
        "        male_styles = ['sportivecasual', 'mods', 'hiphop', 'normcore', 'metrosexual', 'hippie', 'ivy', 'bold']\n",
        "        male_style_map = {style: idx for idx, style in enumerate(male_styles)}\n",
        "        return male_style_map\n",
        "\n",
        "    def _create_female_style_map(self):\n",
        "        # 여성 스타일 목록에 따라 정수로 매핑\n",
        "        female_styles = [\n",
        "            'sportivecasual', 'hiphop', 'oriental', 'normcore', 'lingerie', 'minimal', 'powersuit', 'space',\n",
        "            'ecology', 'disco', 'hippie', 'genderless', 'feminine', 'cityglam', 'punk', 'classic', 'kitsch',\n",
        "            'popart', 'bodyconscious', 'lounge', 'athleisure', 'grunge', 'military'\n",
        "        ]\n",
        "        female_style_map = {style: idx for idx, style in enumerate(female_styles)}\n",
        "        return female_style_map\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.images[idx])\n",
        "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
        "\n",
        "        filename = os.path.basename(img_path)\n",
        "        parts = filename.split('_')\n",
        "\n",
        "        # 성별 레이블 추출 (0: 여성, 1: 남성)\n",
        "        gender_label = 0 if parts[4].startswith('W') else 1\n",
        "\n",
        "        # 스타일 레이블 추출 (성별에 따라 다른 스타일 맵을 사용)\n",
        "        style_label_str = parts[3]\n",
        "        if gender_label == 1:  # 남성일 때\n",
        "            style_label = self.male_style_map.get(style_label_str, -1)\n",
        "            if style_label == -1:\n",
        "                raise ValueError(f\"Style '{style_label_str}' for male is not found in male_style_map.\")\n",
        "        else:  # 여성일 때\n",
        "            style_label = self.female_style_map.get(style_label_str, -1)\n",
        "            if style_label == -1:\n",
        "                raise ValueError(f\"Style '{style_label_str}' for female is not found in female_style_map.\")\n",
        "\n",
        "        # 이미지 전처리 및 증강 적용\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image)\n",
        "            image = augmented['image']\n",
        "\n",
        "        return image, gender_label, style_label\n",
        "\n",
        "\n",
        "\n",
        "# 3. 데이터셋 로드 (이미지들이 하나의 디렉토리에 있는 경우)\n",
        "train_dataset = CustomImageDataset(image_dir, transform=train_transforms)\n",
        "val_dataset = CustomImageDataset(image_dir2, transform=val_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# 4. ResNet-18 모델 설정 (다중 출력 분류)\n",
        "\n",
        "class MultiOutputResNet(nn.Module):\n",
        "    def __init__(self, num_gender_classes=2, num_male_styles=8, num_female_styles=23, dropout_prob=0.5):\n",
        "        super(MultiOutputResNet, self).__init__()\n",
        "        self.resnet = models.resnet18(pretrained=False)\n",
        "\n",
        "        in_features = self.resnet.fc.in_features\n",
        "        self.resnet.fc = nn.Identity()  # fully connected 레이어 제거\n",
        "\n",
        "        # Dropout 레이어\n",
        "        self.dropout = nn.Dropout(p=dropout_prob)\n",
        "\n",
        "        # Batch Normalization 추가\n",
        "        self.bn = nn.BatchNorm1d(in_features)\n",
        "\n",
        "        # 성별 분류 레이어\n",
        "        self.fc_gender = nn.Linear(in_features, num_gender_classes)\n",
        "\n",
        "        # 남성 및 여성 스타일 분류 레이어\n",
        "        self.fc_male_style = nn.Linear(in_features, num_male_styles)\n",
        "        self.fc_female_style = nn.Linear(in_features, num_female_styles)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.resnet(x)\n",
        "        features = self.dropout(features)\n",
        "        features = self.bn(features)  # Batch Normalization 적용\n",
        "\n",
        "        # 성별 분류\n",
        "        gender_output = self.fc_gender(features)\n",
        "\n",
        "        # 남성 및 여성 스타일 분류\n",
        "        male_style_output = self.fc_male_style(features)\n",
        "        female_style_output = self.fc_female_style(features)\n",
        "\n",
        "        return gender_output, male_style_output, female_style_output\n",
        "\n",
        "\n",
        "# 5. 모델 생성 및 가중치 초기화\n",
        "#가중치 초기화 함수\n",
        "def initialize_weights(model):\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, nn.Linear):\n",
        "            torch.nn.init.xavier_uniform_(m.weight)  # Xavier 초기화 (Glorot 초기화)\n",
        "            if m.bias is not None:\n",
        "                torch.nn.init.zeros_(m.bias)  # bias는 0으로 초기화\n",
        "\n",
        "# 모델 생성 후 가중치 초기화 적용\n",
        "num_male_styles = 8   # 남성 스타일 개수\n",
        "num_female_styles = 23 # 여성 스타일 개수\n",
        "model = MultiOutputResNet(num_gender_classes=2, num_male_styles=num_male_styles, num_female_styles=num_female_styles, dropout_prob=0.5)\n",
        "model.apply(initialize_weights)  # 가중치 초기화 수행\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "# Focal Loss 구현\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=2, alpha=None, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = nn.functional.cross_entropy(inputs, targets, reduction='none')\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
        "\n",
        "        if self.alpha is not None:\n",
        "            at = self.alpha.gather(0, targets.data.view(-1))\n",
        "            focal_loss = focal_loss * at\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return focal_loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return focal_loss.sum()\n",
        "        else:\n",
        "            return focal_loss\n",
        "\n",
        "\n",
        "# 손실 함수 (Focal Loss 사용)\n",
        "criterion_gender = FocalLoss(gamma=2)\n",
        "criterion_style = FocalLoss(gamma=2)\n",
        "\n",
        "# 옵티마이저 및 학습률 스케줄러 설정\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)  # 5 epoch마다 학습률 감소\n",
        "\n",
        "# 6. 학습 과정 정의 (진행 퍼센트 표시)\n",
        "def train(model, train_loader, criterion_gender, criterion_style, optimizer):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_gender = 0\n",
        "    correct_style = 0\n",
        "    total = 0\n",
        "\n",
        "    train_loader_tqdm = tqdm(train_loader, desc=\"Training\", unit=\"batch\")\n",
        "\n",
        "    for images, gender_labels, style_labels in train_loader_tqdm:\n",
        "        images, gender_labels, style_labels = images.to(device), gender_labels.to(device), style_labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        gender_output, male_style_output, female_style_output = model(images)\n",
        "\n",
        "        # 성별 분류 손실 계산\n",
        "        loss_gender = criterion_gender(gender_output, gender_labels)\n",
        "\n",
        "        # 성별에 따라 스타일 분류 손실 계산\n",
        "        loss_style = 0\n",
        "        predicted_style = []\n",
        "        for i in range(gender_labels.size(0)):\n",
        "            if gender_labels[i] == 0:  # 여성일 때\n",
        "                loss_style += criterion_style(female_style_output[i].unsqueeze(0), style_labels[i].unsqueeze(0))\n",
        "                predicted_style.append(torch.max(female_style_output[i].unsqueeze(0), 1)[1].item())\n",
        "            else:  # 남성일 때\n",
        "                loss_style += criterion_style(male_style_output[i].unsqueeze(0), style_labels[i].unsqueeze(0))\n",
        "                predicted_style.append(torch.max(male_style_output[i].unsqueeze(0), 1)[1].item())\n",
        "\n",
        "        loss = loss_gender + loss_style  # 총 손실은 성별과 스타일 손실의 합\n",
        "\n",
        "        # 역전파 및 최적화\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient Clipping 적용\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # 성별 분류 정확도 계산\n",
        "        _, predicted_gender = torch.max(gender_output, 1)\n",
        "        total += gender_labels.size(0)\n",
        "        correct_gender += (predicted_gender == gender_labels).sum().item()\n",
        "\n",
        "        # 스타일 분류 정확도 계산\n",
        "        correct_style += (torch.tensor(predicted_style) == style_labels).sum().item()\n",
        "\n",
        "        # 진행 상태 표시\n",
        "        train_loader_tqdm.set_postfix(\n",
        "            loss=loss.item(),\n",
        "            gender_acc=correct_gender / total,\n",
        "            style_acc=correct_style / total  # 스타일 정확도 추가\n",
        "        )\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    gender_accuracy = correct_gender / total\n",
        "    style_accuracy = correct_style / total\n",
        "    return avg_loss, gender_accuracy, style_accuracy\n",
        "\n",
        "\n",
        "def validate(model, val_loader, criterion_gender, criterion_style):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct_gender = 0\n",
        "    correct_style = 0\n",
        "    total = 0\n",
        "\n",
        "    val_loader_tqdm = tqdm(val_loader, desc=\"Validation\", unit=\"batch\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, gender_labels, style_labels in val_loader_tqdm:\n",
        "            images, gender_labels, style_labels = images.to(device), gender_labels.to(device), style_labels.to(device)\n",
        "\n",
        "            gender_output, male_style_output, female_style_output = model(images)\n",
        "\n",
        "            loss_gender = criterion_gender(gender_output, gender_labels)\n",
        "            loss_style = 0\n",
        "            predicted_style = []\n",
        "            for i in range(gender_labels.size(0)):\n",
        "                if gender_labels[i] == 0:\n",
        "                    loss_style += criterion_style(female_style_output[i].unsqueeze(0), style_labels[i].unsqueeze(0))\n",
        "                    predicted_style.append(torch.max(female_style_output[i].unsqueeze(0), 1)[1].item())\n",
        "                else:\n",
        "                    loss_style += criterion_style(male_style_output[i].unsqueeze(0), style_labels[i].unsqueeze(0))\n",
        "                    predicted_style.append(torch.max(male_style_output[i].unsqueeze(0), 1)[1].item())\n",
        "\n",
        "            loss = loss_gender + loss_style\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            _, predicted_gender = torch.max(gender_output, 1)\n",
        "            total += gender_labels.size(0)\n",
        "            correct_gender += (predicted_gender == gender_labels).sum().item()\n",
        "\n",
        "            # 스타일 분류 정확도 계산\n",
        "            correct_style += (torch.tensor(predicted_style) == style_labels).sum().item()\n",
        "\n",
        "            val_loader_tqdm.set_postfix(\n",
        "                loss=loss.item(),\n",
        "                gender_acc=correct_gender / total,\n",
        "                style_acc=correct_style / total  # 스타일 정확도 추가\n",
        "            )\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    gender_accuracy = correct_gender / total\n",
        "    style_accuracy = correct_style / total\n",
        "    return avg_val_loss, gender_accuracy, style_accuracy\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion_gender, criterion_style, optimizer, num_epochs):\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "        avg_loss, gender_acc, style_acc = train(model, train_loader, criterion_gender, criterion_style, optimizer)\n",
        "        print(f\"Training - Loss: {avg_loss:.4f}, Gender Accuracy: {gender_acc:.4f}, Style Accuracy: {style_acc:.4f}\")\n",
        "\n",
        "        avg_val_loss, val_gender_acc, val_style_acc = validate(model, val_loader, criterion_gender, criterion_style)\n",
        "        print(f\"Validation - Loss: {avg_val_loss:.4f}, Gender Accuracy: {val_gender_acc:.4f}, Style Accuracy: {val_style_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6oaB1nZVJkE",
        "outputId": "90c78885-0f95-4de9-c527-f9b4ee8991ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 128/128 [1:16:50<00:00, 36.02s/batch, gender_acc=0.495, loss=23.6, style_acc=0.0958]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training - Loss: 92.3738, Gender Accuracy: 0.4953, Style Accuracy: 0.0958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [08:10<00:00, 16.34s/batch, gender_acc=0.456, loss=52.3, style_acc=0.13]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Loss: 73.0431, Gender Accuracy: 0.4564, Style Accuracy: 0.1304\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 128/128 [37:21<00:00, 17.51s/batch, gender_acc=0.508, loss=15.7, style_acc=0.101]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training - Loss: 87.4223, Gender Accuracy: 0.5076, Style Accuracy: 0.1015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [05:19<00:00, 10.66s/batch, gender_acc=0.463, loss=51.4, style_acc=0.14]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Loss: 69.4011, Gender Accuracy: 0.4627, Style Accuracy: 0.1399\n",
            "Epoch 3/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 128/128 [37:28<00:00, 17.56s/batch, gender_acc=0.505, loss=18.5, style_acc=0.112]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training - Loss: 85.3531, Gender Accuracy: 0.5049, Style Accuracy: 0.1123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [05:24<00:00, 10.80s/batch, gender_acc=0.532, loss=48.2, style_acc=0.15]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Loss: 66.4408, Gender Accuracy: 0.5321, Style Accuracy: 0.1504\n",
            "Epoch 4/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 128/128 [37:37<00:00, 17.63s/batch, gender_acc=0.506, loss=12.3, style_acc=0.099]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training - Loss: 84.5787, Gender Accuracy: 0.5064, Style Accuracy: 0.0990\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [05:14<00:00, 10.49s/batch, gender_acc=0.491, loss=44.8, style_acc=0.177]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Loss: 67.2852, Gender Accuracy: 0.4911, Style Accuracy: 0.1767\n",
            "Epoch 5/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 128/128 [37:17<00:00, 17.48s/batch, gender_acc=0.511, loss=19.5, style_acc=0.112]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training - Loss: 82.9379, Gender Accuracy: 0.5113, Style Accuracy: 0.1120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [05:14<00:00, 10.47s/batch, gender_acc=0.577, loss=50.3, style_acc=0.158]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Loss: 66.8800, Gender Accuracy: 0.5773, Style Accuracy: 0.1577\n",
            "Epoch 6/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 128/128 [37:20<00:00, 17.50s/batch, gender_acc=0.51, loss=16.8, style_acc=0.111]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training - Loss: 83.1708, Gender Accuracy: 0.5098, Style Accuracy: 0.1106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [05:24<00:00, 10.83s/batch, gender_acc=0.535, loss=47.7, style_acc=0.164]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Loss: 66.9871, Gender Accuracy: 0.5352, Style Accuracy: 0.1640\n",
            "Epoch 7/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 128/128 [37:14<00:00, 17.46s/batch, gender_acc=0.508, loss=7.14, style_acc=0.113]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training - Loss: 82.1552, Gender Accuracy: 0.5076, Style Accuracy: 0.1125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [05:17<00:00, 10.57s/batch, gender_acc=0.545, loss=44.1, style_acc=0.146]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Loss: 67.6416, Gender Accuracy: 0.5447, Style Accuracy: 0.1462\n",
            "Epoch 8/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 128/128 [37:01<00:00, 17.35s/batch, gender_acc=0.512, loss=15.8, style_acc=0.117]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training - Loss: 81.5334, Gender Accuracy: 0.5123, Style Accuracy: 0.1167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [05:15<00:00, 10.51s/batch, gender_acc=0.536, loss=48.3, style_acc=0.147]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Loss: 67.1654, Gender Accuracy: 0.5363, Style Accuracy: 0.1472\n",
            "Epoch 9/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 128/128 [37:38<00:00, 17.65s/batch, gender_acc=0.499, loss=21.3, style_acc=0.112]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training - Loss: 81.6312, Gender Accuracy: 0.4993, Style Accuracy: 0.1120\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [05:23<00:00, 10.79s/batch, gender_acc=0.557, loss=49, style_acc=0.151]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Loss: 65.7109, Gender Accuracy: 0.5573, Style Accuracy: 0.1514\n",
            "Epoch 10/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 128/128 [36:56<00:00, 17.32s/batch, gender_acc=0.513, loss=14.7, style_acc=0.119]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training - Loss: 80.6139, Gender Accuracy: 0.5133, Style Accuracy: 0.1192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [05:05<00:00, 10.18s/batch, gender_acc=0.549, loss=48.9, style_acc=0.177]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Loss: 65.3118, Gender Accuracy: 0.5489, Style Accuracy: 0.1767\n",
            "Epoch 11/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 128/128 [36:47<00:00, 17.25s/batch, gender_acc=0.513, loss=18.7, style_acc=0.124]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training - Loss: 78.9073, Gender Accuracy: 0.5130, Style Accuracy: 0.1241\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation: 100%|██████████| 30/30 [05:09<00:00, 10.32s/batch, gender_acc=0.564, loss=47.1, style_acc=0.174]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation - Loss: 65.4238, Gender Accuracy: 0.5636, Style Accuracy: 0.1735\n",
            "Epoch 12/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 128/128 [35:45<00:00, 16.76s/batch, gender_acc=0.51, loss=13.5, style_acc=0.129]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training - Loss: 78.9973, Gender Accuracy: 0.5098, Style Accuracy: 0.1285\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validation:  33%|███▎      | 10/30 [01:46<03:04,  9.23s/batch, gender_acc=0.628, loss=68.4, style_acc=0.194]"
          ]
        }
      ],
      "source": [
        "# 9. 학습 및 검증 데이터 로더 설정 후 학습 실행\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "train_model(model, train_loader, val_loader, criterion_gender, criterion_style, optimizer, num_epochs=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "splIv6Z7VWmw"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN7fRgFCrTJiZCuBwA6QQcd",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}